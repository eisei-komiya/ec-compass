【プロジェクト名】
EC Compass – カスタマイズ可能なE-Commerce製品比較CLIツール
【目的】
・ユーザーが任意の商品（例：マザーボード）に関して、複数のECサイト（価格.com、Amazon、フリマサイトなど）から情報を収集し、
　「価格」「品質」「コスパ」など、ユーザーがYAMLやJSONで定義した柔軟な評価基準に基づいた比較・選定を行う。
・最終的な比較結果をMarkdown形式のレポートとして出力し、どの評価基準でどの商品が優れているのかを直感的に把握できる仕組みを実現する。
【主要な技術スタックと役割】
1. 言語・環境
　・Python 3.9以降
　・CLIツールとして実装し、コマンドラインから実行可能にする。
2. ブラウザ自動操作
　・@Browser-Useを利用して、ECサイトへのアクセスやスクレイピングを自動化する。
　・実際のECサイトのHTMLやDOM情報を取得し、必要な製品情報（価格、スペック、レビューなど）を収集する。
3. 設定ファイル（YAML/JSON）
　・ユーザーが評価基準や検索条件、対象サイトの情報（URL、サイト名など）を柔軟に設定できるようにする。
　・例として、M.2スロットが2つある、PCIE16スロットが2つあるといった特定のカスタム評価基準も定義可能とする。
4. 情報の評価・スコアリング
　・各ECサイトから得た製品情報に対して、設定ファイルに記載された評価基準（重み、閾値、条件チェックなど）を用いてスコアを算出する。
　・評価ロジックはシンプルな加重平均や条件分岐で、今後の拡張性も視野に入れて設計する。
レポート生成のアプローチ
　・従来のプログラム内でのレポート作成だと、柔軟性に欠ける（例：YAMLで定義されたカスタム基準が反映できない）可能性があるため、
　　OpenAIのAPI（GPT-4など）を利用し、AI側でMarkdown形式のレポートを生成する。
　・製品情報と評価基準の両方をプロンプトとして渡すことで、「M.2スロット」や「PCIE16スロット」といったカスタム基準もレポート内に柔軟に反映する。
モジュール分割とアーキテクチャ
　・config_loader.py：YAML/JSON設定ファイルからデータを読み込む
　・scraper.py：@Browser-Useやその他必要な手法でECサイトから情報を収集する
　・evaluator.py：収集した情報に基づき、各評価基準を反映したスコア計算を行う
　・ai_report_generator.py：OpenAI APIを呼び出し、収集結果と評価基準をもとに詳細なMarkdownレポートを生成する
　・main.py：全体のフローを統括するエントリーポイントとして、各モジュールを連携する
──────────────────────────────
【プロジェクトの進め方】
1. 初期段階
　・プロジェクト概要、使用する各モジュールの役割を明確化する
　・設定ファイルの仕様（例：YAMLフォーマット）を決定する
2. スクレイピングモジュールの実装
　・@Browser-Useを用いてECサイトへのアクセス方法、データ取得方法を検討
　・まずはダミーデータで動作確認を行い、後から実際のスクレイピングロジックに置き換える
評価・スコアリングロジックの開発
　・ユーザー定義の評価基準を柔軟に扱えるようなロジックを設計する
　・複数の評価項目に対応し、数値評価および条件チェックを実装する
レポート生成の実装
　・OpenAI API（GPT-4）によるMarkdownレポート作成機能を実装する
　・収集した情報と評価基準をプロンプトとして送信し、AIから生成されたレポートを出力する
5. 統合と検証
　・各モジュールを連携させ、全体の動作確認とデバッグを行う
　・柔軟性のある評価基準とレポート生成が適切に反映されるかをチェックする
──────────────────────────────
【まとめ】
本プロジェクトは、ユーザーが自由にカスタマイズできる設定ファイルを基盤とし、@Browser-Useを活用した自動スクレイピングと、設定に対応した柔軟な評価・スコアリングを行います。そして、プログラム側で固定的にレポートを生成するのではなく、OpenAIのAPIを利用してAI側で動的かつ詳細なMarkdownレポートを作成することで、カスタム基準の反映を可能にするシステムを構築します。これにより、よりユーザーのニーズに合わせた、拡張性と柔軟性を兼ね備えたEC商品比較ツールの実現を目指します。
この方針に沿って、各機能を段階的に実装・統合していく流れとなります。何か追加の質問や補足が必要な点があれば、遠慮なくお知らせください。

## 拡張、精度向上案
- @Browser-Useでの情報取得に難があるなら、たどり着いたurlだけ取ってきて、
そのurlに対して@firecrawlを使ってスクレイピングさせて、情報を取ってくる
- browser_contextを使用して、サイトごとに並列化させる